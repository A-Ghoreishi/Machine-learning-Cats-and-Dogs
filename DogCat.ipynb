{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1QjTTuysnA3",
        "outputId": "b47911bf-c41d-406c-c1ca-640563b6e570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "Train = '/content/drive/My Drive/Train'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = os.listdir(Train)\n",
        "df = []\n",
        "target_size = (64, 64)\n",
        "\n",
        "for file_name in file_names:\n",
        "  try:\n",
        "\n",
        "    with Image.open(os.path.join(Train, file_name)) as img:\n",
        "      width, height = img.size\n",
        "\n",
        "      img_resized = img.resize(target_size)\n",
        "      img_array = np.array(img_resized).astype('float32') / 255.0\n",
        "\n",
        "\n",
        "      df.append({\n",
        "                'file_name': file_name,\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "                'species': 'cat' if 'cat' in file_name else 'dog',\n",
        "                'resized_image': img_array\n",
        "            })\n",
        "  except Exception as e:\n",
        "        # Handle exceptions if image cannot be opened\n",
        "        print(f\"Error processing {file_name}: {e}\")"
      ],
      "metadata": {
        "id": "VEyBgaI_z2Mf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rL7Ypy2z0chG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n",
        "# print(f\"Shape of data: {data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "1jdca0h16gtE",
        "outputId": "c592fbae-5d46-41c9-f2dc-0f3eb89f1a93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       file_name  width  height species  \\\n",
              "0    cat_179.jpg    350     200     cat   \n",
              "1    cat_180.jpg   1600     898     cat   \n",
              "2    cat_229.jpg    225     225     cat   \n",
              "3    cat_235.jpg    640     429     cat   \n",
              "4    cat_276.jpg   1536    1024     cat   \n",
              "..           ...    ...     ...     ...   \n",
              "552  dog_401.jpg    133     200     dog   \n",
              "553   dog_35.jpg    640     635     dog   \n",
              "554  dog_429.jpg    259     194     dog   \n",
              "555  dog_514.jpg   1200     900     dog   \n",
              "556    dog_8.jpg   1920    1080     dog   \n",
              "\n",
              "                                         resized_image  \n",
              "0    [[[0.7372549, 0.6, 0.627451], [0.76862746, 0.6...  \n",
              "1    [[[0.6784314, 0.7411765, 0.8392157], [0.674509...  \n",
              "2    [[[0.5294118, 0.37254903, 0.7254902], [0.52941...  \n",
              "3    [[[0.56078434, 0.6156863, 0.68235296], [0.5529...  \n",
              "4    [[[0.11764706, 0.13333334, 0.13725491], [0.109...  \n",
              "..                                                 ...  \n",
              "552  [[[0.95686275, 0.95686275, 0.95686275], [0.956...  \n",
              "553  [[[0.5137255, 0.8235294, 0.8039216], [0.513725...  \n",
              "554  [[[0.1882353, 0.23921569, 0.02745098], [0.2666...  \n",
              "555  [[[0.7607843, 0.827451, 0.6156863], [0.7568627...  \n",
              "556  [[[0.09803922, 0.08235294, 0.07450981], [0.125...  \n",
              "\n",
              "[557 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dd5bfa6-ab6d-4e19-aa05-c3808ccccf01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>species</th>\n",
              "      <th>resized_image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat_179.jpg</td>\n",
              "      <td>350</td>\n",
              "      <td>200</td>\n",
              "      <td>cat</td>\n",
              "      <td>[[[0.7372549, 0.6, 0.627451], [0.76862746, 0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat_180.jpg</td>\n",
              "      <td>1600</td>\n",
              "      <td>898</td>\n",
              "      <td>cat</td>\n",
              "      <td>[[[0.6784314, 0.7411765, 0.8392157], [0.674509...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cat_229.jpg</td>\n",
              "      <td>225</td>\n",
              "      <td>225</td>\n",
              "      <td>cat</td>\n",
              "      <td>[[[0.5294118, 0.37254903, 0.7254902], [0.52941...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat_235.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>429</td>\n",
              "      <td>cat</td>\n",
              "      <td>[[[0.56078434, 0.6156863, 0.68235296], [0.5529...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat_276.jpg</td>\n",
              "      <td>1536</td>\n",
              "      <td>1024</td>\n",
              "      <td>cat</td>\n",
              "      <td>[[[0.11764706, 0.13333334, 0.13725491], [0.109...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>dog_401.jpg</td>\n",
              "      <td>133</td>\n",
              "      <td>200</td>\n",
              "      <td>dog</td>\n",
              "      <td>[[[0.95686275, 0.95686275, 0.95686275], [0.956...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>dog_35.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>635</td>\n",
              "      <td>dog</td>\n",
              "      <td>[[[0.5137255, 0.8235294, 0.8039216], [0.513725...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>dog_429.jpg</td>\n",
              "      <td>259</td>\n",
              "      <td>194</td>\n",
              "      <td>dog</td>\n",
              "      <td>[[[0.1882353, 0.23921569, 0.02745098], [0.2666...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>dog_514.jpg</td>\n",
              "      <td>1200</td>\n",
              "      <td>900</td>\n",
              "      <td>dog</td>\n",
              "      <td>[[[0.7607843, 0.827451, 0.6156863], [0.7568627...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>dog_8.jpg</td>\n",
              "      <td>1920</td>\n",
              "      <td>1080</td>\n",
              "      <td>dog</td>\n",
              "      <td>[[[0.09803922, 0.08235294, 0.07450981], [0.125...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>557 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dd5bfa6-ab6d-4e19-aa05-c3808ccccf01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1dd5bfa6-ab6d-4e19-aa05-c3808ccccf01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1dd5bfa6-ab6d-4e19-aa05-c3808ccccf01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a8a5c39-4603-480a-b051-4aa37c932f24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a8a5c39-4603-480a-b051-4aa37c932f24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a8a5c39-4603-480a-b051-4aa37c932f24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1843b435-c465-48ff-ac23-b10cd60462ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1843b435-c465-48ff-ac23-b10cd60462ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 557,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 557,\n        \"samples\": [\n          \"cat_97.jpg\",\n          \"dog_473.jpg\",\n          \"cat_243.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 717,\n        \"min\": 133,\n        \"max\": 4272,\n        \"num_unique_values\": 191,\n        \"samples\": [\n          1620,\n          858,\n          308\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 544,\n        \"min\": 133,\n        \"max\": 4272,\n        \"num_unique_values\": 245,\n        \"samples\": [\n          394,\n          533,\n          224\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"dog\",\n          \"cat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resized_image\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "def load_images_and_labels(Train):\n",
        "  for filename in os.listdir(Train):\n",
        "    image_path = os.path.join(Train, filename)\n",
        "\n",
        "    if 'cat' in filename.lower():\n",
        "      label = 1\n",
        "    elif 'dog' in filename.lower():\n",
        "      label = 0\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "    try:\n",
        "            img = tf.keras.utils.load_img(image_path, target_size=(64, 64))\n",
        "            img_array = tf.keras.utils.img_to_array(img)\n",
        "            img_vector = img_array.flatten()\n",
        "\n",
        "            X.append(img_vector)\n",
        "            y.append(label)\n",
        "    except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")"
      ],
      "metadata": {
        "id": "cnbenywPhDpC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Normalize Images?\n",
        "1. Uniform Scale:\n",
        "Images often have pixel values in different ranges (e.g., 0 to 255). Normalizing pixel values (e.g., scaling them to the range [0, 1]) ensures that all features are on the same scale, which helps algorithms learn more effectively.\n",
        "\n",
        "2. Improved Convergence:\n",
        "Normalization can lead to faster and more stable convergence in training, especially for gradient-based algorithms like neural networks. It helps the model to learn more efficiently.\n",
        "\n",
        "3. Prevention of Numerical Issues:\n",
        "Large or small feature values might cause numerical instability during computations. Normalizing values can mitigate such problems."
      ],
      "metadata": {
        "id": "-DhopqlFel9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Does Splitting Data Help in Model Evaluation?\n",
        "1. Generalization Assessment:\n",
        "Splitting data into training and testing sets allows you to evaluate the model on unseen data. This helps you understand how well the model generalizes to new, unseen examples.\n",
        "\n",
        "2. Prevention of Overfitting:\n",
        "If a model performs well on the training set but poorly on the testing set, it might be overfitting. Splitting data helps ensure that the model is not just memorizing the training data but can perform well on new data.\n",
        "\n",
        "3. Model Selection and Tuning:\n",
        "Splitting data allows you to train models on one subset and evaluate them on another. Techniques like cross-validation can further help in selecting the best model and tuning hyperparameters."
      ],
      "metadata": {
        "id": "zPMnRBiXeqJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, lr=0.01,n_iters=1000):\n",
        "      self.lr = lr\n",
        "      self.n_iters = n_iters\n",
        "      self.weight = None\n",
        "      self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      n_sample, n_features = X.shape\n",
        "\n",
        "      #init parameters\n",
        "      self.weight = np.zeros(n_features)\n",
        "      self.bias = 0\n",
        "\n",
        "      #gradient descent\n",
        "\n",
        "      for _ in range(self.n_iters):\n",
        "        # approximate y with linear combination of weights and x, plus bias\n",
        "        linear_model = np.dot(X, self.weight) + self.bias\n",
        "\n",
        "        # apply sigmoid function\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "        # compute gradients\n",
        "        dw = (1 / n_sample) * np.dot(X.T,(y_predicted - y))\n",
        "        db = (1/ n_sample) * np.sum(y_predicted - y)\n",
        "\n",
        "        #update parameters\n",
        "        self.weight -= self.lr * dw\n",
        "        self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "      linear_model = np.dot(X, self.weight) + self.bias\n",
        "      y_predicted = self._sigmoid(linear_model)\n",
        "      y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "      return y_predicted_cls\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "      return 1/(1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "bXBqUqEVIDr-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_images_and_labels(Train)\n",
        "\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "a-XPcPEQOk-S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "cx8tdJKcPpXO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LogisticRegression(lr=0.0001, n_iters=1000)\n",
        "regressor.fit(X_train, y_train)\n",
        "predictions = regressor.predict(X_test)\n",
        "lr_acc = accuracy(y_test, predictions)\n",
        "print(f\"LR accuracy: {lr_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnN4RCC8QFwP",
        "outputId": "25fab5db-79cf-4a37-9d6f-d0bf0ba93c24"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-7e4702e48f0f>:39: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR accuracy: 57.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Use the Sigmoid Activation Function for Binary Classification?\n",
        "1. Output Range: The sigmoid function maps any input to a value between 0 and 1. This property makes it suitable for binary classification problems where the output is a probability, indicating the likelihood of the input belonging to a particular class.\n",
        "\n",
        "2. Interpretability: The sigmoid function provides output in the form of probabilities, which can be directly interpreted as the likelihood of an instance belonging to the positive class (class 1). This is crucial for binary classification tasks.\n",
        "\n",
        "3. Gradient Behavior: The sigmoid function has a well-defined gradient which facilitates backpropagation during training. Although the gradient can become very small (leading to vanishing gradients), it's still useful for many binary classification problems."
      ],
      "metadata": {
        "id": "WzTHWwqge1uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Activation Functions and Their Applications\n",
        "**1. ReLU (Rectified Linear Unit):\n",
        "\n",
        "Formula:\n",
        "ReLU\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "max\n",
        "⁡\n",
        "(\n",
        "0\n",
        ",\n",
        "𝑥\n",
        ")\n",
        "ReLU(x)=max(0,x)\n",
        "Application: Commonly used in hidden layers of neural networks, especially in deep learning. It helps in mitigating the vanishing gradient problem and allows models to learn faster and perform better.\n",
        "**2. Tanh (Hyperbolic Tangent):\n",
        "\n",
        "Formula:\n",
        "tanh\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "𝑒\n",
        "𝑥\n",
        "−\n",
        "𝑒\n",
        "−\n",
        "𝑥\n",
        "𝑒\n",
        "𝑥\n",
        "+\n",
        "𝑒\n",
        "−\n",
        "𝑥\n",
        "tanh(x)=\n",
        "e\n",
        "x\n",
        " +e\n",
        "−x\n",
        "\n",
        "e\n",
        "x\n",
        " −e\n",
        "−x\n",
        "\n",
        "​\n",
        "\n",
        "Application: Similar to the sigmoid function but outputs values in the range [-1, 1]. It is often used in hidden layers where zero-centered data can help with faster convergence.\n",
        "**3. Softmax:\n",
        "\n",
        "Formula:\n",
        "Softmax\n",
        "(\n",
        "𝑥\n",
        "𝑖\n",
        ")\n",
        "=\n",
        "𝑒\n",
        "𝑥\n",
        "𝑖\n",
        "∑\n",
        "𝑗\n",
        "𝑒\n",
        "𝑥\n",
        "𝑗\n",
        "Softmax(x\n",
        "i\n",
        "​\n",
        " )=\n",
        "∑\n",
        "j\n",
        "​\n",
        " e\n",
        "x\n",
        "j\n",
        "​\n",
        "\n",
        "\n",
        "e\n",
        "x\n",
        "i\n",
        "​\n",
        "\n",
        "\n",
        "​\n",
        "\n",
        "Application: Used in the output layer for multi-class classification problems. It converts logits (raw prediction values) into probabilities for each class, which sum to 1.\n",
        "**4. Leaky ReLU:\n",
        "\n",
        "Formula:\n",
        "Leaky ReLU\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "max\n",
        "⁡\n",
        "(\n",
        "0.01\n",
        "𝑥\n",
        ",\n",
        "𝑥\n",
        ")\n",
        "Leaky ReLU(x)=max(0.01x,x)\n",
        "Application: Addresses the problem of dying ReLUs (where neurons become inactive and always output zero) by allowing a small, non-zero gradient when\n",
        "𝑥\n",
        "<\n",
        "0\n",
        "x<0.\n",
        "**5. ELU (Exponential Linear Unit):\n",
        "\n",
        "Formula:\n",
        "ELU\n",
        "(\n",
        "𝑥\n",
        ")\n",
        "=\n",
        "{\n",
        "𝑥\n",
        "if\n",
        "𝑥\n",
        ">\n",
        "0\n",
        "𝛼\n",
        "(\n",
        "𝑒\n",
        "𝑥\n",
        "−\n",
        "1\n",
        ")\n",
        "if\n",
        "𝑥\n",
        "≤\n",
        "0\n",
        "ELU(x)={\n",
        "x\n",
        "α(e\n",
        "x\n",
        " −1)\n",
        "​\n",
        "  \n",
        "if x>0\n",
        "if x≤0\n",
        "​\n",
        "\n",
        "Application: Similar to ReLU but with an exponential term for negative inputs, which helps reduce the problem of vanishing gradients and speeds up learning."
      ],
      "metadata": {
        "id": "OHsjzqfre2ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Use Cross-Entropy Loss Instead of Mean Squared Error for Classification?\n",
        "**1. Probabilistic Interpretation: Cross-Entropy Loss, also known as Log Loss, is specifically designed for classification problems where the output represents probabilities. It measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
        "\n",
        "**2. Gradient Behavior: Cross-Entropy Loss provides better gradients for classification tasks compared to Mean Squared Error (MSE). This is because the gradient of Cross-Entropy Loss with respect to the model's output is proportional to the difference between the predicted probability and the actual label, leading to more effective weight updates.\n",
        "\n",
        "**3. Handling Imbalanced Classes: Cross-Entropy Loss tends to work better with imbalanced classes. It penalizes wrong predictions more heavily, which helps in learning from class imbalance.\n",
        "\n",
        "**4. Convergence: Cross-Entropy Loss generally leads to faster convergence in classification problems compared to MSE. This is due to its nature of penalizing wrong predictions more effectively.\n",
        "\n",
        "**5. MSE Limitation: MSE is typically used for regression tasks where the output is continuous. For classification tasks, especially binary classification, MSE does not align well with the probabilistic nature of classification and can lead to suboptimal performance."
      ],
      "metadata": {
        "id": "vwMIlaNofBYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating KNN with the Same Metrics as Logistic Regression**\n",
        "\n",
        "To evaluate the KNN model using the same metrics as Logistic Regression, follow these steps:\n",
        "\n",
        "Train and Predict with KNN:"
      ],
      "metadata": {
        "id": "mlLLuFMnfi_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "knn_acc = accuracy(y_test, y_pred_knn)\n",
        "print(f\"k-NN accuracy: {knn_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDjrvWUzSqMH",
        "outputId": "f483094f-77b3-43fb-b90d-1fea23851543"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN accuracy: 55.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of K-Nearest Neighbors (KNN) in Classification Tasks\n",
        "K-Nearest Neighbors (KNN) is a simple and intuitive classification algorithm that classifies data points based on the majority label among their k nearest neighbors in the feature space.\n",
        "\n",
        "How KNN Works:\n",
        "\n",
        "Distance Calculation:\n",
        "For a given test sample, KNN calculates the distance between this sample and all training samples. Common distance metrics include Euclidean distance, Manhattan distance, and Minkowski distance.\n",
        "\n",
        "Neighbor Selection:\n",
        "The algorithm selects the k nearest training samples to the test sample.\n",
        "\n",
        "Majority Voting:\n",
        "The class label of the test sample is determined by the majority vote of its k nearest neighbors. The most frequent class label among these neighbors is assigned to the test sample.\n",
        "\n",
        "Performance Characteristics:\n",
        "\n",
        "Non-parametric:\n",
        "KNN does not assume any specific distribution for the data, making it flexible but potentially computationally expensive.\n",
        "\n",
        "Lazy Learner:\n",
        "KNN does not explicitly train a model; instead, it performs computation during the prediction phase, which can be slow with large datasets."
      ],
      "metadata": {
        "id": "mpgw52zcfJvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison with Logistic Regression**\n",
        "\n",
        "**1. Model Assumptions:**\n",
        "\n",
        "Logistic Regression:\n",
        "Assumes a linear relationship between the input features and the log-odds of the outcome. It models the probability of the positive class directly and uses a sigmoid function for binary classification.\n",
        "\n",
        "KNN:\n",
        "Makes no assumptions about the form of the decision boundary. It is a non-parametric method that bases its classification on the local neighborhood of each test point.\n",
        "\n",
        "**2. Complexity and Computation:**\n",
        "\n",
        "Logistic Regression:\n",
        "Generally has lower computational complexity during prediction because it uses a model with learned parameters. Training involves optimization but prediction is straightforward.\n",
        "\n",
        "KNN:\n",
        "Computationally intensive during prediction, especially with large datasets, as it requires calculating distances to all training samples. Training is faster because it simply stores the data.\n",
        "\n",
        "**3. Handling Non-linearity:**\n",
        "\n",
        "Logistic Regression:\n",
        "Limited to linear decision boundaries unless extended with polynomial features or interaction terms.\n",
        "\n",
        "KNN:\n",
        "Can handle complex and non-linear decision boundaries because it relies on the local structure of the data.\n",
        "\n",
        "**4. Sensitivity to Outliers:\n",
        "\n",
        "Logistic Regression:\n",
        "Sensitive to outliers, as they can affect the fitted decision boundary.\n",
        "\n",
        "KNN:\n",
        "Sensitive to noisy or irrelevant features and outliers, as these can influence the distance calculations and neighbor selection."
      ],
      "metadata": {
        "id": "7wl37_OmfMpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create and train the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "dt_acc = accuracy(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree accuracy: {dt_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMWTyGuoXgPx",
        "outputId": "bbcf115d-35a2-4681-c924-639a68863920"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy: 56.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy(y_test, y_pred_rf)\n",
        "print(f\"Random Forest accuracy: {rf_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au1PXLgRbN50",
        "outputId": "c6899b20-afa3-4f77-9246-469c7bfd4376"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest accuracy: 65.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of Models for Image Classification\n",
        "Based on your project where you've implemented Logistic Regression (LR), K-Nearest Neighbors (KNN), Decision Trees (DT), and Random Forest (RF) on image data, and observed that RF had the highest accuracy, here’s a detailed comparison:\n",
        "\n",
        "1. Performance of Each Model\n",
        "Logistic Regression (LR)\n",
        "Description: Logistic Regression is a linear model that works well for binary classification problems. It might struggle with complex patterns in image data unless you use feature engineering or dimensionality reduction.\n",
        "Accuracy: Often lower for raw image data without pre-processing.\n",
        "K-Nearest Neighbors (KNN)\n",
        "Description: KNN is a non-parametric algorithm that classifies data points based on the majority class among their nearest neighbors. It can be computationally expensive and slower with large image datasets.\n",
        "Accuracy: Can be high for small datasets but might degrade with larger or more complex data.\n",
        "Decision Trees (DT)\n",
        "Description: Decision Trees split the data based on feature values and can capture complex patterns. They can be prone to overfitting if not properly tuned.\n",
        "Accuracy: Can be effective with proper tuning, but may not perform as well as ensemble methods like Random Forest.\n",
        "Random Forest (RF)\n",
        "Description: Random Forest is an ensemble method that builds multiple decision trees and averages their predictions to improve performance and reduce overfitting.\n",
        "Accuracy: Typically provides high accuracy and generalizes well on diverse datasets, including image data.\n",
        "2. Why Random Forest Outperforms the Others\n",
        "**1. Complexity Handling:\n",
        "\n",
        "RF: Combines multiple decision trees to handle complex patterns and interactions in the data, making it well-suited for image classification tasks.\n",
        "LR, KNN, DT: May struggle with the high-dimensional and complex nature of image data. LR is linear, KNN can be slow and sensitive to dimensionality, and DT may overfit.\n",
        "**2. Overfitting:\n",
        "\n",
        "RF: Reduces overfitting by averaging predictions across multiple trees, which helps in generalizing better to unseen data.\n",
        "LR, KNN, DT: Can overfit, especially without proper regularization or tuning.\n",
        "**3. Feature Importance:\n",
        "\n",
        "RF: Provides feature importance metrics, which can help in understanding which features (or image segments) are most influential in classification.\n",
        "LR, KNN, DT: May not provide clear insights into feature importance, especially for raw pixel values.\n",
        "3. Implementation Comparison\n",
        "Ease of Implementation:\n",
        "\n",
        "LR: Easier to implement but may require significant pre-processing and feature engineering for image data.\n",
        "KNN: Simple to implement but can become slow with large datasets. Requires careful selection of the number of neighbors (k).\n",
        "DT: Easy to understand and visualize but requires tuning hyperparameters to avoid overfitting.\n",
        "RF: More complex due to multiple trees but typically provides robust performance with fewer hyperparameters to tune compared to DT.\n",
        "4. Hyperparameter Tuning for Random Forest\n",
        "Important Hyperparameters to Tune:\n",
        "\n",
        "n_estimators: Number of trees in the forest. Increasing this usually improves accuracy but also increases computation time.\n",
        "max_depth: Maximum depth of each tree. Controls the complexity of the trees.\n",
        "min_samples_split: Minimum number of samples required to split an internal node. Helps in preventing overfitting.\n",
        "min_samples_leaf: Minimum number of samples required to be at a leaf node. A higher value can reduce overfitting.\n",
        "\n",
        "5. Summary\n",
        "Accuracy: Random Forest generally outperforms Logistic Regression, KNN, and Decision Trees in image classification tasks due to its ability to handle complex data and reduce overfitting.\n",
        "Implementation: Random Forest might be more complex to set up initially but often provides the best performance for image data compared to the other models.\n",
        "Hyperparameter Tuning: Essential for optimizing Random Forest performance, and can significantly impact the accuracy and effectiveness of the model.\n",
        "If Random Forest consistently provides the highest accuracy on your dataset, it is likely the most suitable model for your image classification task. Make sure to report these findings and observations in your project to demonstrate the effectiveness of Random Forest in comparison to other models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rK_cJ8aVgPIh"
      }
    }
  ]
}